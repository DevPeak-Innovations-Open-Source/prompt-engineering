version: '3.9'

services:
  mini-n8n-backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: mini-n8n-backend
    ports:
      - "8000:8000"
    environment:
      # Application Settings
      - APP_NAME=mini_n8n
      - DEBUG=false
      
      # Database Settings
      - DATABASE_URL=sqlite+aiosqlite:///./data/mini_n8n.db
      
      # LLM Settings (OpenAI)
      - LLM_PROVIDER=openai
      - OPENAI_API_KEY=${OPENAI_API_KEY:-your-openai-api-key}
      - OPENAI_MODEL=gpt-4
      
      # Vertex AI Settings (uncomment if using Vertex AI)
      # - LLM_PROVIDER=vertexai
      # - VERTEXAI_PROJECT_ID=${VERTEXAI_PROJECT_ID}
      # - VERTEXAI_LOCATION=us-central1
      # - VERTEXAI_MODEL=gemini-pro
      
      # Workflow Settings
      - MAX_WORKFLOW_EXECUTION_TIME=3600
      - MAX_NODE_RETRIES=3
    
    volumes:
      - ./backend/data:/app/data
      - ./backend/app:/app/app
    
    restart: unless-stopped
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    
    networks:
      - mini-n8n-network

networks:
  mini-n8n-network:
    driver: bridge

volumes:
  mini-n8n-data:

